dataset_configs:
  train:
    output_sequences_path: ./datasets/doggy_data/train_pt
  val:
    output_sequences_path: ./datasets/doggy_data/val_pt
  test:
    output_sequences_path: ./datasets/doggy_data/test_pt
  corrupted_percentage: 0.15
  mean_noise_span_length: 3.0
  extra_ids: 100
model_configs:
  model_type: t5_simple
  tokenizer: Base
  tokenizer_path: ./datasets/vocab/test.model
  hyperparameters:
    max_seq_len: 150
    hidden_dim: 128
    nhead: 4
    num_layers: 2
    ff_size: 2048
    regularizers: []
    dropout: 0.1
    batch_size: 32
    optimizer: "adam"
    learning_rate: 1e-4
    grad_accumulation_step: 1
    immunogenicity_as_value: False
training_configs:
  epochs: 100
  eval_steps: 1
  checkpoint_steps: 1
  device: 0
  random_seed: 1234
  outputs_dir: "train_outputs"
  training_type: "pt"
  wandb_project: "doggy_ai_pt"
  wandb_name: "doggy_ai_pt_small"
  verbose: True
  verbose_output_file: "debug_outputs"
  samples_output_file: "samples_output"
validation_configs:
  substitution_matrix: "PAM30"
  gap_insertion_penalty: -11
  gap_extension_penalty: -1
  sample_method: "beam"
  beam_width: 15
  top_k: 1
